{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0625f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import minitorch\n",
    "from minitorch.cuda_kernel_ops import CudaKernelOps\n",
    "backend = minitorch.TensorBackend(CudaKernelOps)\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e86f835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betta threadIdx.x 0 -2.410292 -0.193901 0.788223 -0.359631\n",
      "betta threadIdx.x 1 0.827177 0.706287 0.240376 0.401762\n",
      "betta threadIdx.x 0 -1.232705 0.729160 -0.904135 0.184053\n",
      "betta threadIdx.x 1 0.269257 -0.791408 2.071791 -0.326014\n",
      "betta threadIdx.x 0 -0.492562 1.727008 -1.047601 -0.141781\n",
      "betta threadIdx.x 1 -1.315368 1.143262 -0.489627 0.616669\n",
      "betta threadIdx.x 0 -1.710606 0.772420 -1.495746 0.503250\n",
      "betta threadIdx.x 1 0.121531 1.197968 0.723928 -0.112746\n",
      "betta threadIdx.x 0 0.784291 -2.200967 -0.116408 0.131355\n",
      "betta threadIdx.x 1 0.676478 0.934529 0.655939 -0.865217\n",
      "betta threadIdx.x 0 -0.394311 -1.536533 1.092929 0.715345\n",
      "betta threadIdx.x 1 0.212143 -0.075685 1.358073 -1.371962\n",
      "betta threadIdx.x 0 0.576854 -1.756566 0.850936 0.699395\n",
      "betta threadIdx.x 1 -1.500286 0.306515 -0.173604 0.996756\n",
      "betta threadIdx.x 0 0.841621 -1.225876 -1.064749 0.529245\n",
      "betta threadIdx.x 1 0.976593 -1.163514 -0.299666 1.406345\n",
      "betta threadIdx.x 0 -0.132305 -0.558172 -0.252767 -0.942241\n",
      "betta threadIdx.x 1 1.864121 1.415743 -1.063119 -0.331259\n",
      "betta threadIdx.x 0 0.154221 -1.109948 -1.697393 0.264068\n",
      "betta threadIdx.x 1 1.186261 -0.716669 0.836513 1.082947\n",
      "\n",
      "[\n",
      "\t[0.841621 -1.225877 -1.064749 0.529245 0.976593 -1.163514 -0.299666 1.406346]\n",
      "\t[0.576854 -1.756566 0.850936 0.699395 -1.500286 0.306515 -0.173604 0.996756]\n",
      "\t[-1.232705 0.729160 -0.904135 0.184053 0.269257 -0.791408 2.071791 -0.326014]\n",
      "\t[-1.710606 0.772420 -1.495746 0.503250 0.121531 1.197968 0.723928 -0.112746]\n",
      "\t[-0.132305 -0.558172 -0.252767 -0.942241 1.864121 1.415743 -1.063119 -0.331259]\n",
      "\t[0.154221 -1.109948 -1.697393 0.264068 1.186261 -0.716669 0.836513 1.082947]\n",
      "\t[-0.394311 -1.536533 1.092929 0.715345 0.212143 -0.075685 1.358072 -1.371962]\n",
      "\t[0.784291 -2.200968 -0.116408 0.131355 0.676479 0.934529 0.655940 -0.865217]\n",
      "\t[-2.410293 -0.193901 0.788223 -0.359631 0.827178 0.706288 0.240376 0.401763]\n",
      "\t[-0.492562 1.727008 -1.047601 -0.141781 -1.315368 1.143262 -0.489627 0.616669]]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "rows = 10\n",
    "hidden_dim = 8\n",
    "\n",
    "def rand(shape):\n",
    "    return np.random.rand(*shape)\n",
    "\n",
    "inp = rand((rows, hidden_dim))\n",
    "out_grad = rand((rows,hidden_dim))\n",
    "gamma = rand((hidden_dim,))\n",
    "beta = rand((hidden_dim,))\n",
    "\n",
    "\n",
    "def custom():\n",
    "    inp_mt = minitorch.tensor_from_numpy(inp, backend=backend, requires_grad=True)\n",
    "    gamma_mt = minitorch.tensor_from_numpy(gamma, backend=backend, requires_grad=True)\n",
    "    beta_mt = minitorch.tensor_from_numpy(beta, backend=backend, requires_grad=True)\n",
    "    out_grad_mt = minitorch.tensor_from_numpy(out_grad, backend=backend, requires_grad=True)\n",
    "\n",
    "    out_mt = inp_mt.layernorm(gamma_mt, beta_mt)\n",
    "    out_mt.backward(out_grad_mt)\n",
    "\n",
    "    return inp_mt.grad, gamma_mt.grad, beta_mt.grad, inp_mt, gamma_mt, beta_mt\n",
    "\n",
    "def baseline():\n",
    "    f_input = minitorch.tensor_from_numpy(inp, backend=backend, requires_grad=True)\n",
    "    f_gamma = minitorch.tensor_from_numpy(gamma, backend=backend, requires_grad=True)\n",
    "    f_out_grad = minitorch.tensor_from_numpy(out_grad, backend=backend, requires_grad=True)\n",
    "\n",
    "    f_means = f_input.mean(dim=1)\n",
    "    f_vars = f_input.var(dim=1)\n",
    "    f_stds = minitorch.tensor(np.sqrt(f_vars.to_numpy()).reshape(-1, 1).tolist(), backend=backend, requires_grad=True)\n",
    "\n",
    "    xhat = (f_input - f_means) / f_stds\n",
    "    print(xhat)\n",
    "    dxhat = f_out_grad * f_gamma\n",
    "    f_betta_grad = f_out_grad.sum(dim=0)\n",
    "    f_gamma_grad = (f_out_grad * xhat).sum(dim=0)\n",
    "    dinp = dxhat.sum(dim=1) + xhat * (dxhat * xhat).sum(dim=1)\n",
    "    dinp = dxhat - dinp / hidden_dim\n",
    "    dinp = dinp / f_stds\n",
    "    return dinp, f_gamma_grad, f_betta_grad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     return res\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "inp_grad_mt, gamma_mt, beta_mt, my_inp,g,b = custom()\n",
    "dinp, f_gamma_grad, f_betta_grad = baseline()\n",
    "# print(c-b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6887b35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[\n",
       "\t[0.363159 -0.973019 0.567064 -1.343835 0.311715 0.419770 0.539747 0.115399]\n",
       "\t[0.896951 -0.698703 -0.395386 -1.072312 0.843488 -0.885398 0.366174 0.945186]\n",
       "\t[-0.068733 -0.738745 1.149902 -1.119724 0.607371 -0.916680 0.485833 0.600775]\n",
       "\t[0.136526 -0.894889 -0.821604 -0.203212 -0.449466 -0.352787 0.677535 1.907897]\n",
       "\t[1.878921 -0.510564 1.074184 -0.929947 -0.122341 -0.401434 0.235396 -1.224215]\n",
       "\t[2.284641 -1.410709 1.486890 -0.864101 -0.780670 -1.269956 -1.014273 1.568181]\n",
       "\t[0.354428 -0.399201 1.114915 -0.660827 -0.220450 -0.426768 -0.321817 0.559721]\n",
       "\t[1.091704 -0.154234 -0.273991 -0.715171 0.971482 -0.876906 -0.662936 0.620052]\n",
       "\t[0.538298 -0.839852 1.704438 -0.910067 -0.567035 -0.324313 -0.011291 0.409821]\n",
       "\t[0.836467 -0.291591 -0.642730 -0.508428 -0.046064 -0.498319 0.027369 1.123297]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44821851-6e88-476a-8c48-965d93297090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[\n",
       "\t[0.363159 -0.973018 0.567064 -1.343835 0.311715 0.419770 0.539747 0.115399]\n",
       "\t[0.896951 -0.698703 -0.395386 -1.072311 0.843488 -0.885398 0.366174 0.945186]\n",
       "\t[-0.068733 -0.738745 1.149902 -1.119724 0.607371 -0.916680 0.485833 0.600775]\n",
       "\t[0.136525 -0.894889 -0.821604 -0.203211 -0.449466 -0.352786 0.677535 1.907897]\n",
       "\t[1.878920 -0.510564 1.074184 -0.929947 -0.122341 -0.401434 0.235396 -1.224215]\n",
       "\t[2.284640 -1.410709 1.486890 -0.864101 -0.780670 -1.269956 -1.014273 1.568180]\n",
       "\t[0.354428 -0.399201 1.114915 -0.660828 -0.220450 -0.426768 -0.321817 0.559721]\n",
       "\t[1.091704 -0.154234 -0.273991 -0.715171 0.971482 -0.876906 -0.662935 0.620052]\n",
       "\t[0.538298 -0.839852 1.704437 -0.910067 -0.567035 -0.324313 -0.011291 0.409821]\n",
       "\t[0.836467 -0.291591 -0.642730 -0.508428 -0.046064 -0.498320 0.027369 1.123297]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_grad_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b27d0-800b-4298-b409-d53f141123a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
